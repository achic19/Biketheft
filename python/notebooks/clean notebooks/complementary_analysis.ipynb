{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import calendar\n",
    "from scipy.stats import chi2_contingency\n",
    "from IPython.display import display\n",
    "import os, re\n",
    "project_folder =os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "decade = 'Q34_1'\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "data_path = f'{project_folder}/python/notebooks/output/general/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "      level_0  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  index        StartDate  \\\n0           0             2           718         745    745   5/3/2022 19:05   \n1           1             3           313         323    323  4/27/2022 16:30   \n2           2             4          1409        1492   1492  5/11/2022 14:54   \n3           3             5          1603        1710   1710  5/15/2022 20:21   \n4           4             6             5           7      7  4/22/2022 11:46   \n...       ...           ...           ...         ...    ...              ...   \n1816     1816          1818          1773        1967   1967  5/16/2022 17:58   \n1817     1817          1819          1786        1981   1981   6/1/2022 14:44   \n1818     1818          1820          1795        1990   1990   6/2/2022 14:51   \n1819     1819          1821          1823        2021   2021  5/24/2022 12:17   \n1820     1820          1822          1824        2022   2022    6/8/2022 3:19   \n\n              EndDate      Status        IPAddress  Progress  ...  \\\n0      5/3/2022 19:19  IP Address    208.98.223.42       100  ...   \n1     4/27/2022 16:44  IP Address   99.171.110.253       100  ...   \n2     5/11/2022 15:00  IP Address   76.103.138.149       100  ...   \n3     5/15/2022 20:27  IP Address     68.149.96.52       100  ...   \n4     4/22/2022 11:53  IP Address     97.113.1.186       100  ...   \n...               ...         ...              ...       ...  ...   \n1816  5/16/2022 18:03  IP Address     73.189.49.55        82  ...   \n1817   6/1/2022 14:51  IP Address    72.194.49.254       100  ...   \n1818   6/2/2022 14:56  IP Address    107.122.81.38       100  ...   \n1819  5/24/2022 12:20  IP Address   174.90.223.242        69  ...   \n1820    6/8/2022 3:30  IP Address  108.211.181.111       100  ...   \n\n                                                    Q40     Q40_3_TEXT  \\\n0     A bicycle registry/recovery system (e.g., Bike...            NaN   \n1                                                 Email            NaN   \n2                                                 Email            NaN   \n3                                                 Email            NaN   \n4                                                 Email            NaN   \n...                                                 ...            ...   \n1816                                                NaN            NaN   \n1817                                              Email            NaN   \n1818                            Other (please specify):       Facebook   \n1819                                                NaN            NaN   \n1820                            Other (please specify):  acquientance    \n\n             lat        lon  score            stolen_bikes_place  country  \\\n0    -113.490140  53.545450  100.0          Edmonton,Alberta,CAN      CAN   \n1    -117.874460  33.749580  100.0      Santa Ana,California,USA      USA   \n2    -121.885420  37.338650  100.0       San Jose,California,USA      USA   \n3    -113.490140  53.545450  100.0          Edmonton,Alberta,CAN      CAN   \n4    -122.329450  47.603570  100.0        Seattle,Washington,USA      USA   \n...          ...        ...    ...                           ...      ...   \n1816 -122.285410  38.299110  100.0           Napa,California,USA      USA   \n1817 -119.728880  34.441470  100.0  Santa Barbara,California,USA      USA   \n1818 -119.699050  34.419380  100.0  Santa Barbara,California,USA      USA   \n1819 -114.057141  51.045113  100.0           Calgary,Alberta,CAN      CAN   \n1820 -122.419640  37.777120  100.0  San Francisco,California,USA      USA   \n\n               city       state  Q34_1  \n0          Edmonton     Alberta  1930s  \n1         Santa Ana  California  1930s  \n2          San Jose  California  1940s  \n3          Edmonton     Alberta  1940s  \n4           Seattle  Washington  1940s  \n...             ...         ...    ...  \n1816           Napa  California    NaN  \n1817  Santa Barbara  California    NaN  \n1818  Santa Barbara  California    NaN  \n1819        Calgary     Alberta    NaN  \n1820  San Francisco  California    NaN  \n\n[1821 rows x 87 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>Unnamed: 0.2</th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>index</th>\n      <th>StartDate</th>\n      <th>EndDate</th>\n      <th>Status</th>\n      <th>IPAddress</th>\n      <th>Progress</th>\n      <th>...</th>\n      <th>Q40</th>\n      <th>Q40_3_TEXT</th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>score</th>\n      <th>stolen_bikes_place</th>\n      <th>country</th>\n      <th>city</th>\n      <th>state</th>\n      <th>Q34_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2</td>\n      <td>718</td>\n      <td>745</td>\n      <td>745</td>\n      <td>5/3/2022 19:05</td>\n      <td>5/3/2022 19:19</td>\n      <td>IP Address</td>\n      <td>208.98.223.42</td>\n      <td>100</td>\n      <td>...</td>\n      <td>A bicycle registry/recovery system (e.g., Bike...</td>\n      <td>NaN</td>\n      <td>-113.490140</td>\n      <td>53.545450</td>\n      <td>100.0</td>\n      <td>Edmonton,Alberta,CAN</td>\n      <td>CAN</td>\n      <td>Edmonton</td>\n      <td>Alberta</td>\n      <td>1930s</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>313</td>\n      <td>323</td>\n      <td>323</td>\n      <td>4/27/2022 16:30</td>\n      <td>4/27/2022 16:44</td>\n      <td>IP Address</td>\n      <td>99.171.110.253</td>\n      <td>100</td>\n      <td>...</td>\n      <td>Email</td>\n      <td>NaN</td>\n      <td>-117.874460</td>\n      <td>33.749580</td>\n      <td>100.0</td>\n      <td>Santa Ana,California,USA</td>\n      <td>USA</td>\n      <td>Santa Ana</td>\n      <td>California</td>\n      <td>1930s</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>4</td>\n      <td>1409</td>\n      <td>1492</td>\n      <td>1492</td>\n      <td>5/11/2022 14:54</td>\n      <td>5/11/2022 15:00</td>\n      <td>IP Address</td>\n      <td>76.103.138.149</td>\n      <td>100</td>\n      <td>...</td>\n      <td>Email</td>\n      <td>NaN</td>\n      <td>-121.885420</td>\n      <td>37.338650</td>\n      <td>100.0</td>\n      <td>San Jose,California,USA</td>\n      <td>USA</td>\n      <td>San Jose</td>\n      <td>California</td>\n      <td>1940s</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>5</td>\n      <td>1603</td>\n      <td>1710</td>\n      <td>1710</td>\n      <td>5/15/2022 20:21</td>\n      <td>5/15/2022 20:27</td>\n      <td>IP Address</td>\n      <td>68.149.96.52</td>\n      <td>100</td>\n      <td>...</td>\n      <td>Email</td>\n      <td>NaN</td>\n      <td>-113.490140</td>\n      <td>53.545450</td>\n      <td>100.0</td>\n      <td>Edmonton,Alberta,CAN</td>\n      <td>CAN</td>\n      <td>Edmonton</td>\n      <td>Alberta</td>\n      <td>1940s</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>6</td>\n      <td>5</td>\n      <td>7</td>\n      <td>7</td>\n      <td>4/22/2022 11:46</td>\n      <td>4/22/2022 11:53</td>\n      <td>IP Address</td>\n      <td>97.113.1.186</td>\n      <td>100</td>\n      <td>...</td>\n      <td>Email</td>\n      <td>NaN</td>\n      <td>-122.329450</td>\n      <td>47.603570</td>\n      <td>100.0</td>\n      <td>Seattle,Washington,USA</td>\n      <td>USA</td>\n      <td>Seattle</td>\n      <td>Washington</td>\n      <td>1940s</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1816</th>\n      <td>1816</td>\n      <td>1818</td>\n      <td>1773</td>\n      <td>1967</td>\n      <td>1967</td>\n      <td>5/16/2022 17:58</td>\n      <td>5/16/2022 18:03</td>\n      <td>IP Address</td>\n      <td>73.189.49.55</td>\n      <td>82</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-122.285410</td>\n      <td>38.299110</td>\n      <td>100.0</td>\n      <td>Napa,California,USA</td>\n      <td>USA</td>\n      <td>Napa</td>\n      <td>California</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1817</th>\n      <td>1817</td>\n      <td>1819</td>\n      <td>1786</td>\n      <td>1981</td>\n      <td>1981</td>\n      <td>6/1/2022 14:44</td>\n      <td>6/1/2022 14:51</td>\n      <td>IP Address</td>\n      <td>72.194.49.254</td>\n      <td>100</td>\n      <td>...</td>\n      <td>Email</td>\n      <td>NaN</td>\n      <td>-119.728880</td>\n      <td>34.441470</td>\n      <td>100.0</td>\n      <td>Santa Barbara,California,USA</td>\n      <td>USA</td>\n      <td>Santa Barbara</td>\n      <td>California</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1818</th>\n      <td>1818</td>\n      <td>1820</td>\n      <td>1795</td>\n      <td>1990</td>\n      <td>1990</td>\n      <td>6/2/2022 14:51</td>\n      <td>6/2/2022 14:56</td>\n      <td>IP Address</td>\n      <td>107.122.81.38</td>\n      <td>100</td>\n      <td>...</td>\n      <td>Other (please specify):</td>\n      <td>Facebook</td>\n      <td>-119.699050</td>\n      <td>34.419380</td>\n      <td>100.0</td>\n      <td>Santa Barbara,California,USA</td>\n      <td>USA</td>\n      <td>Santa Barbara</td>\n      <td>California</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1819</th>\n      <td>1819</td>\n      <td>1821</td>\n      <td>1823</td>\n      <td>2021</td>\n      <td>2021</td>\n      <td>5/24/2022 12:17</td>\n      <td>5/24/2022 12:20</td>\n      <td>IP Address</td>\n      <td>174.90.223.242</td>\n      <td>69</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-114.057141</td>\n      <td>51.045113</td>\n      <td>100.0</td>\n      <td>Calgary,Alberta,CAN</td>\n      <td>CAN</td>\n      <td>Calgary</td>\n      <td>Alberta</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1820</th>\n      <td>1820</td>\n      <td>1822</td>\n      <td>1824</td>\n      <td>2022</td>\n      <td>2022</td>\n      <td>6/8/2022 3:19</td>\n      <td>6/8/2022 3:30</td>\n      <td>IP Address</td>\n      <td>108.211.181.111</td>\n      <td>100</td>\n      <td>...</td>\n      <td>Other (please specify):</td>\n      <td>acquientance</td>\n      <td>-122.419640</td>\n      <td>37.777120</td>\n      <td>100.0</td>\n      <td>San Francisco,California,USA</td>\n      <td>USA</td>\n      <td>San Francisco</td>\n      <td>California</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1821 rows × 87 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_general = pd.read_csv(f'{project_folder}/data/process/final_geo_coding.csv', skiprows=[1, 2]).reset_index()\n",
    "data_general['Q34_1'] = data_general['Q34'].dropna().map(lambda x:str(int(x/10)*10) +'s')\n",
    "data_general"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                     level_0  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  index  \\\nQ10                                                                           \nDon’t know/not sure       61            61            61          61     61   \nNo                      1124          1124          1124        1124   1124   \nYes                      634           634           634         634    634   \n\n                     StartDate  EndDate  Status  IPAddress  Progress  ...  \\\nQ10                                                                   ...   \nDon’t know/not sure         61       61      61         61        61  ...   \nNo                        1124     1124    1124       1124      1124  ...   \nYes                        634      634     634        634       634  ...   \n\n                      Q40  Q40_3_TEXT   lat   lon  score  stolen_bikes_place  \\\nQ10                                                                            \nDon’t know/not sure    56           2    61    61     61                  61   \nNo                   1054         102  1124  1124   1124                1124   \nYes                   592          40   634   634    634                 634   \n\n                     country  city  state  Q34_1  \nQ10                                               \nDon’t know/not sure       61    55     61     54  \nNo                      1124  1077   1124   1033  \nYes                      634   600    634    580  \n\n[3 rows x 86 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>Unnamed: 0.2</th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>index</th>\n      <th>StartDate</th>\n      <th>EndDate</th>\n      <th>Status</th>\n      <th>IPAddress</th>\n      <th>Progress</th>\n      <th>...</th>\n      <th>Q40</th>\n      <th>Q40_3_TEXT</th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>score</th>\n      <th>stolen_bikes_place</th>\n      <th>country</th>\n      <th>city</th>\n      <th>state</th>\n      <th>Q34_1</th>\n    </tr>\n    <tr>\n      <th>Q10</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Don’t know/not sure</th>\n      <td>61</td>\n      <td>61</td>\n      <td>61</td>\n      <td>61</td>\n      <td>61</td>\n      <td>61</td>\n      <td>61</td>\n      <td>61</td>\n      <td>61</td>\n      <td>61</td>\n      <td>...</td>\n      <td>56</td>\n      <td>2</td>\n      <td>61</td>\n      <td>61</td>\n      <td>61</td>\n      <td>61</td>\n      <td>61</td>\n      <td>55</td>\n      <td>61</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>No</th>\n      <td>1124</td>\n      <td>1124</td>\n      <td>1124</td>\n      <td>1124</td>\n      <td>1124</td>\n      <td>1124</td>\n      <td>1124</td>\n      <td>1124</td>\n      <td>1124</td>\n      <td>1124</td>\n      <td>...</td>\n      <td>1054</td>\n      <td>102</td>\n      <td>1124</td>\n      <td>1124</td>\n      <td>1124</td>\n      <td>1124</td>\n      <td>1124</td>\n      <td>1077</td>\n      <td>1124</td>\n      <td>1033</td>\n    </tr>\n    <tr>\n      <th>Yes</th>\n      <td>634</td>\n      <td>634</td>\n      <td>634</td>\n      <td>634</td>\n      <td>634</td>\n      <td>634</td>\n      <td>634</td>\n      <td>634</td>\n      <td>634</td>\n      <td>634</td>\n      <td>...</td>\n      <td>592</td>\n      <td>40</td>\n      <td>634</td>\n      <td>634</td>\n      <td>634</td>\n      <td>634</td>\n      <td>634</td>\n      <td>600</td>\n      <td>634</td>\n      <td>580</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 86 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_general.groupby('Q10').count()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "index                                                          0\nStartDate                                             Start Date\nEndDate                                                 End Date\nStatus                                             Response Type\nIPAddress                                             IP Address\n                                     ...                        \nQ38            What is the highest level of education you hav...\nQ39            What do you consider your main ethnic origin o...\nQ39_10_TEXT    What do you consider your main ethnic origin o...\nQ40            Where did you hear about this survey? - Select...\nQ40_3_TEXT     Where did you hear about this survey? - Other ...\nName: 0, Length: 75, dtype: object"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# show the questions\n",
    "pd.read_csv(f'{project_folder}/data/process/new_data.csv', skiprows=[2]).reset_index().iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Q2': 'Part',\n 'Q6': 'Day time',\n 'Q7': 'Is locked',\n 'Q8': 'Locked type',\n 'Q9': 'Theft location',\n 'Q10': 'Is registered',\n 'Q11': 'Where report',\n 'Q12': 'Is insured',\n 'Q13': 'Value approx. ',\n 'Q14': 'Is electric',\n 'Q15': 'Bicycle type',\n 'Q17': 'Is university',\n 'Q18': 'Is recovered',\n 'Q19': 'Is online',\n 'Q20': 'How recovered',\n 'Q21': 'Is police assist',\n 'Q23': 'Recovery location',\n 'Q24': 'Recovery condition ',\n 'Q34_1': 'Birth by decade',\n 'Q35': 'Gender',\n 'Q36': 'Income',\n 'Q37': 'Number of bicycles ',\n 'Q38': 'Education',\n 'Q39': 'Ethnic origin'}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions ={'Q2':'part','Q6':'day_time','Q7':'is_locked','Q8':'locked_type','Q9':'theft_location','Q10':'is_registered','Q11':'where_report','Q12':'is_insured','Q13':'value_approx. ','Q14':'is_electric','Q15':'bicycle_type','Q17':'is_university','Q18':'is_recovered','Q19':'is_online','Q20':'how_recovered','Q21':'is_police_assist','Q23':'recovery_location','Q24':'recovery_condition ','Q34_1': 'birth by decade', 'Q35': 'gender', 'Q36': 'income','Q37':'number_of_bicycles ', 'Q38': 'education', 'Q39': 'ethnic_origin'}\n",
    "questions ={item[0]: item[1].capitalize().replace('_',' ') for item in questions.items()}\n",
    "questions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "new_tables = []\n",
    "percentage = 'Percentage'\n",
    "count = 'Count'\n",
    "# Specific code for birth year\n",
    "\n",
    "for pair in questions.items():\n",
    "    # statistic by count (display also by percentage)\n",
    "    # pair = ('Q39','ethnic_origin')\n",
    "    question = pair[0]\n",
    "    #  code for birth year has already conducted\n",
    "\n",
    "    # work on specific question\n",
    "    table_0 = DataFrame(data_general.groupby(question).count()['level_0'].sort_values(ascending=False).rename(count))\n",
    "    # Clean unnecessary data and white space\n",
    "    table = table_0.set_index(table_0.index.map(lambda x: re.sub(\"\\(.*?\\)\", \"\", x)).str.replace('      ', '').str.strip()) if question !='Q34_1' \\\n",
    "        else table_0\n",
    "\n",
    "    table[percentage] = round(table[count] / table[count].sum() * 100, 1)\n",
    "\n",
    "\n",
    "    # create multiindex\n",
    "    test = table.copy()\n",
    "    test['new_index'] = pair[1]\n",
    "    table.index = pd.MultiIndex.from_arrays([test['new_index'],table.index])\n",
    "    table.sort_values(by=percentage,ascending=False)\n",
    "    table[percentage] = table[percentage].astype(str)+'%'\n",
    "    new_tables.append(table.iloc[:3])\n",
    "\n",
    "whole_data = DataFrame(data=pd.concat(new_tables))\n",
    "whole_data.index.names = ['Question', 'Response']\n",
    "whole_data.to_excel(f'{data_path}/table.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def get_the_highest(table_updated, table_to_agg):\n",
    "# This method aggregates small numbers of response types while maintaining 10% percentiles\n",
    "    if table_to_agg[percentage].sum()<10:\n",
    "        if len(table_to_agg)==1:\n",
    "            # No aggregation is required\n",
    "            table_updated = table_updated.append(table_to_agg)\n",
    "        else:\n",
    "            table_updated.loc['Aggregated Responses'] = round(table_to_agg.sum(), 1)\n",
    "        return table_updated\n",
    "    else:\n",
    "        table_updated = table_updated.append(table_to_agg.iloc[0])\n",
    "        return get_the_highest(table_updated, table_to_agg.iloc[1:])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def sub_aggregate_def(indices:list,j,sum)-> list:\n",
    "    \"\"\"\n",
    "    add all the response types that together are less than 10%\n",
    "    :param indices: list to updata\n",
    "    :param j: next response types index to check\n",
    "    :param sum: the current percentile sum\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    temp_sum = sub_aggregate.iloc[j][percentage] +sum\n",
    "    if temp_sum>10:\n",
    "        return indices\n",
    "    else:\n",
    "        indices.append(j)\n",
    "        if j+1 <len_sub_aggregate:\n",
    "            indices = sub_aggregate_def(indices,j+1,temp_sum)\n",
    "    return indices\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "new_tables = {}\n",
    "percentage = 'percentage'\n",
    "# Specific code for birth year\n",
    "\n",
    "\n",
    "for pair in questions.items():\n",
    "    # statistic by count (display also by percentage)\n",
    "    # pair = ('Q39','ethnic_origin')\n",
    "    question = pair[0]\n",
    "    #  code for birth year has already conducted\n",
    "    if question =='Q34':\n",
    "        table_0 = DataFrame(data_general.groupby('Q34').count()['level_0'].sort_values(ascending=False).rename('count'))\n",
    "        # convert year to decade.\n",
    "        decade = 'decade'\n",
    "        table_0[decade] = table_0.index.map(lambda x:int(x/10)*10)\n",
    "        table = DataFrame(table_0.groupby(decade).sum()['count'].sort_values(ascending=False))\n",
    "        table[percentage] = round(table['count']/table['count'].sum()*100,1)\n",
    "        new_tables['Q34_1_birth'] = table.sort_values(by=decade)\n",
    "        continue\n",
    "\n",
    "    # work on specific question\n",
    "    table_0 = DataFrame(data_general.groupby(question).count()['level_0'].sort_values(ascending=False).rename('count'))\n",
    "    # Clean unnecessary data and white space\n",
    "    table = table_0.set_index(table_0.index.map(lambda x: re.sub(\"\\(.*?\\)\",\"\",x)).str.replace('      ','').str.strip())\n",
    "\n",
    "    table[percentage] = round(table['count']/table['count'].sum()*100,1)\n",
    "    # Aggregate responses type with less than 10 responses\n",
    "    table_aggregate = table[table[percentage]<10]\n",
    "    table_new = table.copy()\n",
    "\n",
    "    if len(table_aggregate)>1:\n",
    "         # There are more than 1 values with less than 10% respondent\n",
    "        table_new =table[table[percentage]>10]\n",
    "        table_add = get_the_highest(DataFrame(columns=table_aggregate.columns),table_aggregate)\n",
    "        # There are more than 1 values with less than 10% respondents that not part of aggregation process before\n",
    "        if len(table_add)>2:\n",
    "            sub_aggregate = table_add.iloc[:-1].sort_values(by=percentage)\n",
    "            i =0\n",
    "            len_sub_aggregate = len(sub_aggregate)\n",
    "            while i < len_sub_aggregate:\n",
    "                if i ==len_sub_aggregate -1:\n",
    "                    indices = [i]\n",
    "                else:\n",
    "                    indices = sub_aggregate_def([i],i+1,sub_aggregate.iloc[i][percentage])\n",
    "                # aggregate sll the responses type based on indices\n",
    "                temp_df =sub_aggregate.iloc[indices]\n",
    "                table_new.loc[' OR '.join(list(temp_df.index))] = temp_df.sum()\n",
    "                i = indices[-1]+1\n",
    "            table_new =table_new.append(table_add.iloc[-1])\n",
    "        else:\n",
    "            table_new = table_new.append(table_add)\n",
    "\n",
    "    # add the new table into tables dictionary\n",
    "    # table_new.sort_values(by=percentage,ascending=False,inplace=True)\n",
    "    # table_new[percentage] = table[percentage].astype(str)+'%'\n",
    "    new_tables[f'{question}_{pair[1]}'] = table_new.sort_values(by=percentage,ascending=False)\n",
    "    # break\n",
    "with pd.ExcelWriter(f\"{project_folder}/python/notebooks/output/general/output.xlsx\") as writer:\n",
    "    [item[1].to_excel(writer, sheet_name=item[0]) for item in new_tables.items()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Run code without aggregation\n",
    "new_tables = {}\n",
    "percentage = 'percentage'\n",
    "# Specific code for birth year\n",
    "for pair in questions.items():\n",
    "    # statistic by count (display also by percentage)\n",
    "    # pair = ('Q39','ethnic_origin')\n",
    "    question = pair[0]\n",
    "    #  code for birth year has already conducted\n",
    "    if question =='Q34':\n",
    "        table_0 = DataFrame(data_general.groupby('Q34').count()['level_0'].sort_values(ascending=False).rename('count'))\n",
    "        # convert year to decade.\n",
    "        table_0[decade] = table_0.index.map(lambda x:int(x/10)*10)\n",
    "        table = DataFrame(table_0.groupby(decade).sum()['count'].sort_values(ascending=False))\n",
    "        table[percentage] = round(table['count']/table['count'].sum()*100,1)\n",
    "        new_tables['Q34_1_birth'] = table.sort_values(by=decade)\n",
    "        continue\n",
    "\n",
    "    # work on specific question\n",
    "    table_0 = DataFrame(data_general.groupby(question).count()['level_0'].sort_values(ascending=False).rename('count'))\n",
    "    # Clean unnecessary data and white space\n",
    "    table = table_0.set_index(table_0.index.map(lambda x: re.sub(\"\\(.*?\\)\",\"\",x)).str.replace('      ','').str.strip())\n",
    "\n",
    "    table[percentage] = round(table['count']/table['count'].sum()*100,1)\n",
    "\n",
    "    # add the new table into tables dictionary\n",
    "    new_tables[f'{question}_{pair[1]}'] = table.sort_values(by=percentage,ascending=False)\n",
    "    # break\n",
    "with pd.ExcelWriter(f\"{project_folder}/python/notebooks/output/general/no_agg.xlsx\") as writer:\n",
    "    [item[1].to_excel(writer, sheet_name=item[0]) for item in new_tables.items()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "634"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# registered bicycles\n",
    "# United States VS Canada - Recovery\n",
    "# data_general_0 = data_general[data_general['Q18']=='Yes (including if damaged) ']\n",
    "data_general_0 = data_general[data_general['Q18']=='Yes (including if damaged) ']\n",
    "len(data_general_0)\n",
    "new_tables = {}\n",
    "percentage = 'percentage'\n",
    "countries_names = list(data_general_0['country'].drop_duplicates())\n",
    "\n",
    "countries_data = {countries_names[0]:data_general_0[data_general_0['country']==countries_names[0]],\n",
    "                  countries_names[1]:data_general_0[data_general_0['country']==countries_names[1]]}\n",
    "\n",
    "for pair in questions.items():\n",
    "    by_countries_table = DataFrame(columns=countries_names)\n",
    "    # statistic by count (display also by percentage)\n",
    "    # pair = ('Q34', 'birth')\n",
    "    question = pair[0]\n",
    "    #  code for birth year has already conducted\n",
    "    if question =='Q34':\n",
    "        for item in countries_names:\n",
    "            country_data= countries_data[item]\n",
    "            # Specific code for birth year\n",
    "            table_0 = DataFrame(country_data.groupby('Q34').count()['level_0'].sort_values(ascending=False).rename('count'))\n",
    "            # convert year to decade.\n",
    "            decade = 'Q34_1'\n",
    "            table_0[decade] = table_0.index.map(lambda x:int(x/10)*10)\n",
    "            table = DataFrame(table_0.groupby(decade).sum()['count'].sort_values(ascending=False))\n",
    "            by_countries_table[item] = round(table['count']/table['count'].sum()*100,1)\n",
    "\n",
    "        by_countries_table.columns = by_countries_table.columns + '(%)'\n",
    "        by_countries_table.fillna(0,inplace=True)\n",
    "        new_tables[f'{question}_{pair[1]}'] = by_countries_table.sort_values(by=decade)\n",
    "        continue\n",
    "    for item in countries_names:\n",
    "        country_data= countries_data[item]\n",
    "        # work on specific question\n",
    "        table_0 = DataFrame(country_data.groupby(question).count()['level_0'].sort_values(ascending=False).rename('count'))\n",
    "        # Clean unnecessary data and white space\n",
    "        table = table_0.set_index(table_0.index.map(lambda x: re.sub(\"\\(.*?\\)\",\"\",x)).str.replace('      ','').str.strip())\n",
    "        by_countries_table[item] = round(table['count']/table['count'].sum()*100,1)\n",
    "    by_countries_table.columns = by_countries_table.columns + '(%)'\n",
    "    by_countries_table.fillna(0,inplace=True)\n",
    "        # add the new table into tables dictionary\n",
    "    new_tables[f'{question}_{pair[1]}'] = by_countries_table.sort_values(by='USA(%)',ascending=False)\n",
    "    # break\n",
    "with pd.ExcelWriter(f\"{project_folder}/python/notebooks/output/general/usa_canada_recovery.xlsx\") as writer:\n",
    "    [item[1].to_excel(writer, sheet_name=item[0]) for item in new_tables.items()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def check_type(value_check):\n",
    "    r\"\"\"\n",
    "    if it is tuple the name and the column names are different\n",
    "    :param value_check:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return (value_check[0], '_'.join(value_check)) if isinstance(value_check, tuple) else (value_check, value_check)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def bivariate_analysis_update(data_to_group:DataFrame, main_vars_to_group:list, secondary_vars:list, field_to_count:str, my_data_path:str):\n",
    "    r\"\"\"\n",
    "    It goes over the dictionary and calculate the cross relation between the variable inside\n",
    "    :param my_data_path: he code creates a new folder here if it does not already exist, and it saves the new Excel files there.\n",
    "    :param data_to_group: data to work on\n",
    "    :param field_to_count: which field to retain after groupby and counting\n",
    "    :param main_vars_to_group:\n",
    "    :param secondary_vars:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    os.makedirs(my_data_path,exist_ok = True)\n",
    "    for main_var in main_vars_to_group:\n",
    "        col_name,print_main = check_type(main_var)\n",
    "        print(f'\\n{print_main}')\n",
    "        new_tables_data = {}\n",
    "        data1 = data_to_group[~data_to_group[col_name].isin(['No Response', 'no response'])].dropna(subset= col_name)\n",
    "        for other in secondary_vars:\n",
    "            col_secondary,print_secondary = check_type(other)\n",
    "            if col_secondary ==col_name:\n",
    "                continue\n",
    "            print(f'{print_secondary}\\t',end=\"\")\n",
    "            data2 = data1[~data_to_group[col_secondary].isin(['No Response', 'no response'])].dropna(subset=col_secondary)\n",
    "            sum_field = data2.groupby(col_name).count()[field_to_count].rename('count')\n",
    "            # GroupBy two questions (one of which is main_var)\n",
    "            table_00 = DataFrame(data2.groupby([col_name, col_secondary]).count()[field_to_count].rename(''))\n",
    "            # Get the data in readable structure\n",
    "            table_0 =table_00.unstack(fill_value=0)\n",
    "            # Clean columns and index\n",
    "            table_0.columns = table_0.columns.droplevel()\n",
    "\n",
    "            # get percentage (questions variables for each group)\n",
    "            old_columns =table_0.columns\n",
    "            table_2 = table_0.copy()\n",
    "            table_2[old_columns.astype(str) +' (%)'] = round(table_0.div(sum_field, axis=0) * 100, 1).astype(str)+'%'\n",
    "            table_2['sum_field'] = sum_field\n",
    "            if print_main == 'Q13_estimate_val':\n",
    "                # estimate_val should be sorted by value\n",
    "                table_2['sort_by_value'] = dic_df_estimate_val\n",
    "                new_tables_data[f'{print_secondary}'] =table_2.sort_values(by='sort_by_value')\n",
    "            else:\n",
    "                new_tables_data[f'{print_secondary}'] =table_2.sort_values(by='sum_field',ascending=False)\n",
    "        with pd.ExcelWriter(f\"{my_data_path}/{print_main}.xlsx\") as writer:\n",
    "            [item[1].to_excel(writer, sheet_name=item[0]) for item in new_tables_data.items()]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Optional\n",
    "DataFrame(data_general['Q13'].unique()).to_csv(f'{data_path}/Q13_answers.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q11_report_loc\n",
      "Q2_part\tQ6_day_time\tQ7_is_locked\tQ8_locked_type\tQ9_theft_location\tQ10_is_regi\tQ12_is_insured\tQ14_is_electric\tQ15_bike_type\tQ17_is_university\tQ18_is_recovered\tQ19_is_online\tQ20_how_recovered\tQ21_is_police_assist\tQ23_recovery_loc\tQ24_con_recovery\t"
     ]
    }
   ],
   "source": [
    "\n",
    "# find correlation between two variables - Demographic\n",
    "# demographic_data= {'Q11':'report_loc','Q13': 'estimate_val','Q34_1': 'birth', 'Q35': 'gender', 'Q36': 'income','Q37':'number_of_bicycles ', 'Q38': 'education', 'Q39': 'ethnic_origin'}\n",
    "demographic_data= {'Q11':'report_loc'}\n",
    "other_data ={'Q2': 'part', 'Q6': 'day_time', 'Q7': 'is_locked', 'Q8': 'locked_type', 'Q9': 'theft_location', 'Q10': 'is_regi', 'Q11': 'report_loc', 'Q12': 'is_insured', 'Q14': 'is_electric', 'Q15': 'bike_type', 'Q17': 'is_university','Q18':'is_recovered', 'Q19': 'is_online','Q20':'how_recovered', 'Q21': 'is_police_assist', 'Q23': 'recovery_loc', 'Q24': 'con_recovery'}\n",
    "# for estimate_val\n",
    "dic_df_estimate_val = pd.read_csv(f'{data_path}/Q13_answers.csv',index_col='value')\n",
    "\n",
    "demographic_data= [item for item in demographic_data.items()]\n",
    "other_data  = [item for item in other_data.items()]\n",
    "bivariate_analysis_update(data_to_group=data_general,main_vars_to_group=demographic_data,secondary_vars=other_data,field_to_count='level_0',my_data_path=f'{data_path}/demographic')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q18_is_recovered\n",
      "Q2_part\tQ6_day_time\tQ7_is_locked\tQ8_locked_type\tQ9_theft_location\tQ10_is_regi\tQ11_report_loc\tQ12_is_insured\tQ13_estimate_val\tQ14_is_electric\tQ15_bike_type\tQ17_is_university\tQ34_1_birth\tQ35_gender\tQ36_income\tQ37_number_of_bicycles \tQ38_education\tQ39_ethnic_origin\t\n",
      "Q19_is_online\n",
      "Q2_part\tQ6_day_time\tQ7_is_locked\tQ8_locked_type\tQ9_theft_location\tQ10_is_regi\tQ11_report_loc\tQ12_is_insured\tQ13_estimate_val\tQ14_is_electric\tQ15_bike_type\tQ17_is_university\tQ34_1_birth\tQ35_gender\tQ36_income\tQ37_number_of_bicycles \tQ38_education\tQ39_ethnic_origin\t\n",
      "Q21_is_police_assist\n",
      "Q2_part\tQ6_day_time\tQ7_is_locked\tQ8_locked_type\tQ9_theft_location\tQ10_is_regi\tQ11_report_loc\tQ12_is_insured\tQ13_estimate_val\tQ14_is_electric\tQ15_bike_type\tQ17_is_university\tQ34_1_birth\tQ35_gender\tQ36_income\tQ37_number_of_bicycles \tQ38_education\tQ39_ethnic_origin\t\n",
      "Q23_recovery_loc\n",
      "Q2_part\tQ6_day_time\tQ7_is_locked\tQ8_locked_type\tQ9_theft_location\tQ10_is_regi\tQ11_report_loc\tQ12_is_insured\tQ13_estimate_val\tQ14_is_electric\tQ15_bike_type\tQ17_is_university\tQ34_1_birth\tQ35_gender\tQ36_income\tQ37_number_of_bicycles \tQ38_education\tQ39_ethnic_origin\t\n",
      "Q24_con_recovery\n",
      "Q2_part\tQ6_day_time\tQ7_is_locked\tQ8_locked_type\tQ9_theft_location\tQ10_is_regi\tQ11_report_loc\tQ12_is_insured\tQ13_estimate_val\tQ14_is_electric\tQ15_bike_type\tQ17_is_university\tQ34_1_birth\tQ35_gender\tQ36_income\tQ37_number_of_bicycles \tQ38_education\tQ39_ethnic_origin\t"
     ]
    }
   ],
   "source": [
    "\n",
    "# find correlation between two variables -Recovery\n",
    "\n",
    "recovery_data= {'Q18':'is_recovered', 'Q19': 'is_online', 'Q21': 'is_police_assist', 'Q23': 'recovery_loc', 'Q24': 'con_recovery'}\n",
    "other_data ={'Q2': 'part', 'Q6': 'day_time', 'Q7': 'is_locked', 'Q8': 'locked_type', 'Q9': 'theft_location', 'Q10': 'is_regi', 'Q11': 'report_loc', 'Q12': 'is_insured', 'Q13': 'estimate_val', 'Q14': 'is_electric', 'Q15': 'bike_type', 'Q17': 'is_university','Q34_1': 'birth', 'Q35': 'gender', 'Q36': 'income','Q37':'number_of_bicycles ', 'Q38': 'education', 'Q39': 'ethnic_origin'}\n",
    "recovery_data= [item for item in recovery_data.items()]\n",
    "other_data  = [item for item in other_data.items()]\n",
    "bivariate_analysis_update(data_to_group=data_general,main_vars_to_group=recovery_data,secondary_vars=other_data,field_to_count='level_0',my_data_path=f'{data_path}/recovery')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "      level_0  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  index        StartDate  \\\n0           0             2           718         745    745   5/3/2022 19:05   \n3           3             5          1603        1710   1710  5/15/2022 20:21   \n4           4             6             5           7      7  4/22/2022 11:46   \n6           6             8          1214        1277   1277  5/11/2022 11:00   \n9           9            11           604         630    630   5/3/2022 14:19   \n...       ...           ...           ...         ...    ...              ...   \n1813     1813          1815          1762        1952   1952  5/13/2022 12:47   \n1814     1814          1816          1765        1956   1956  5/14/2022 18:15   \n1815     1815          1817          1768        1961   1961  5/15/2022 22:05   \n1819     1819          1821          1823        2021   2021  5/24/2022 12:17   \n1820     1820          1822          1824        2022   2022    6/8/2022 3:19   \n\n              EndDate      Status        IPAddress  Progress  ...  \\\n0      5/3/2022 19:19  IP Address    208.98.223.42       100  ...   \n3     5/15/2022 20:27  IP Address     68.149.96.52       100  ...   \n4     4/22/2022 11:53  IP Address     97.113.1.186       100  ...   \n6     5/11/2022 11:04  IP Address    73.231.228.78       100  ...   \n9      5/3/2022 14:27  IP Address    50.99.114.237       100  ...   \n...               ...         ...              ...       ...  ...   \n1813  5/13/2022 12:51  IP Address    136.25.110.98        82  ...   \n1814  5/14/2022 18:17  IP Address   72.134.228.254        69  ...   \n1815  5/15/2022 22:09  IP Address       24.17.91.3        69  ...   \n1819  5/24/2022 12:20  IP Address   174.90.223.242        69  ...   \n1820    6/8/2022 3:30  IP Address  108.211.181.111       100  ...   \n\n                                                    Q40     Q40_3_TEXT  \\\n0     A bicycle registry/recovery system (e.g., Bike...            NaN   \n3                                                 Email            NaN   \n4                                                 Email            NaN   \n6                                                 Email            NaN   \n9                                                 Email            NaN   \n...                                                 ...            ...   \n1813                                                NaN            NaN   \n1814                                                NaN            NaN   \n1815                                                NaN            NaN   \n1819                                                NaN            NaN   \n1820                            Other (please specify):  acquientance    \n\n             lat        lon  score            stolen_bikes_place  country  \\\n0    -113.490140  53.545450  100.0          Edmonton,Alberta,CAN      CAN   \n3    -113.490140  53.545450  100.0          Edmonton,Alberta,CAN      CAN   \n4    -122.329450  47.603570  100.0        Seattle,Washington,USA      USA   \n6    -122.419640  37.777120  100.0  San Francisco,California,USA      USA   \n9    -113.490140  53.545450  100.0          Edmonton,Alberta,CAN      CAN   \n...          ...        ...    ...                           ...      ...   \n1813 -122.419640  37.777120  100.0  San Francisco,California,USA      USA   \n1814 -118.245450  34.053570  100.0    Los Angeles,California,USA      USA   \n1815 -122.329450  47.603570  100.0        Seattle,Washington,USA      USA   \n1819 -114.057141  51.045113  100.0           Calgary,Alberta,CAN      CAN   \n1820 -122.419640  37.777120  100.0  San Francisco,California,USA      USA   \n\n               city       state  Q34_1  \n0          Edmonton     Alberta  1930s  \n3          Edmonton     Alberta  1940s  \n4           Seattle  Washington  1940s  \n6     San Francisco  California  1940s  \n9          Edmonton     Alberta  1940s  \n...             ...         ...    ...  \n1813  San Francisco  California    NaN  \n1814    Los Angeles  California    NaN  \n1815        Seattle  Washington    NaN  \n1819        Calgary     Alberta    NaN  \n1820  San Francisco  California    NaN  \n\n[586 rows x 87 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>Unnamed: 0.2</th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>index</th>\n      <th>StartDate</th>\n      <th>EndDate</th>\n      <th>Status</th>\n      <th>IPAddress</th>\n      <th>Progress</th>\n      <th>...</th>\n      <th>Q40</th>\n      <th>Q40_3_TEXT</th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>score</th>\n      <th>stolen_bikes_place</th>\n      <th>country</th>\n      <th>city</th>\n      <th>state</th>\n      <th>Q34_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2</td>\n      <td>718</td>\n      <td>745</td>\n      <td>745</td>\n      <td>5/3/2022 19:05</td>\n      <td>5/3/2022 19:19</td>\n      <td>IP Address</td>\n      <td>208.98.223.42</td>\n      <td>100</td>\n      <td>...</td>\n      <td>A bicycle registry/recovery system (e.g., Bike...</td>\n      <td>NaN</td>\n      <td>-113.490140</td>\n      <td>53.545450</td>\n      <td>100.0</td>\n      <td>Edmonton,Alberta,CAN</td>\n      <td>CAN</td>\n      <td>Edmonton</td>\n      <td>Alberta</td>\n      <td>1930s</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>5</td>\n      <td>1603</td>\n      <td>1710</td>\n      <td>1710</td>\n      <td>5/15/2022 20:21</td>\n      <td>5/15/2022 20:27</td>\n      <td>IP Address</td>\n      <td>68.149.96.52</td>\n      <td>100</td>\n      <td>...</td>\n      <td>Email</td>\n      <td>NaN</td>\n      <td>-113.490140</td>\n      <td>53.545450</td>\n      <td>100.0</td>\n      <td>Edmonton,Alberta,CAN</td>\n      <td>CAN</td>\n      <td>Edmonton</td>\n      <td>Alberta</td>\n      <td>1940s</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>6</td>\n      <td>5</td>\n      <td>7</td>\n      <td>7</td>\n      <td>4/22/2022 11:46</td>\n      <td>4/22/2022 11:53</td>\n      <td>IP Address</td>\n      <td>97.113.1.186</td>\n      <td>100</td>\n      <td>...</td>\n      <td>Email</td>\n      <td>NaN</td>\n      <td>-122.329450</td>\n      <td>47.603570</td>\n      <td>100.0</td>\n      <td>Seattle,Washington,USA</td>\n      <td>USA</td>\n      <td>Seattle</td>\n      <td>Washington</td>\n      <td>1940s</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>8</td>\n      <td>1214</td>\n      <td>1277</td>\n      <td>1277</td>\n      <td>5/11/2022 11:00</td>\n      <td>5/11/2022 11:04</td>\n      <td>IP Address</td>\n      <td>73.231.228.78</td>\n      <td>100</td>\n      <td>...</td>\n      <td>Email</td>\n      <td>NaN</td>\n      <td>-122.419640</td>\n      <td>37.777120</td>\n      <td>100.0</td>\n      <td>San Francisco,California,USA</td>\n      <td>USA</td>\n      <td>San Francisco</td>\n      <td>California</td>\n      <td>1940s</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>11</td>\n      <td>604</td>\n      <td>630</td>\n      <td>630</td>\n      <td>5/3/2022 14:19</td>\n      <td>5/3/2022 14:27</td>\n      <td>IP Address</td>\n      <td>50.99.114.237</td>\n      <td>100</td>\n      <td>...</td>\n      <td>Email</td>\n      <td>NaN</td>\n      <td>-113.490140</td>\n      <td>53.545450</td>\n      <td>100.0</td>\n      <td>Edmonton,Alberta,CAN</td>\n      <td>CAN</td>\n      <td>Edmonton</td>\n      <td>Alberta</td>\n      <td>1940s</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1813</th>\n      <td>1813</td>\n      <td>1815</td>\n      <td>1762</td>\n      <td>1952</td>\n      <td>1952</td>\n      <td>5/13/2022 12:47</td>\n      <td>5/13/2022 12:51</td>\n      <td>IP Address</td>\n      <td>136.25.110.98</td>\n      <td>82</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-122.419640</td>\n      <td>37.777120</td>\n      <td>100.0</td>\n      <td>San Francisco,California,USA</td>\n      <td>USA</td>\n      <td>San Francisco</td>\n      <td>California</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1814</th>\n      <td>1814</td>\n      <td>1816</td>\n      <td>1765</td>\n      <td>1956</td>\n      <td>1956</td>\n      <td>5/14/2022 18:15</td>\n      <td>5/14/2022 18:17</td>\n      <td>IP Address</td>\n      <td>72.134.228.254</td>\n      <td>69</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-118.245450</td>\n      <td>34.053570</td>\n      <td>100.0</td>\n      <td>Los Angeles,California,USA</td>\n      <td>USA</td>\n      <td>Los Angeles</td>\n      <td>California</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1815</th>\n      <td>1815</td>\n      <td>1817</td>\n      <td>1768</td>\n      <td>1961</td>\n      <td>1961</td>\n      <td>5/15/2022 22:05</td>\n      <td>5/15/2022 22:09</td>\n      <td>IP Address</td>\n      <td>24.17.91.3</td>\n      <td>69</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-122.329450</td>\n      <td>47.603570</td>\n      <td>100.0</td>\n      <td>Seattle,Washington,USA</td>\n      <td>USA</td>\n      <td>Seattle</td>\n      <td>Washington</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1819</th>\n      <td>1819</td>\n      <td>1821</td>\n      <td>1823</td>\n      <td>2021</td>\n      <td>2021</td>\n      <td>5/24/2022 12:17</td>\n      <td>5/24/2022 12:20</td>\n      <td>IP Address</td>\n      <td>174.90.223.242</td>\n      <td>69</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-114.057141</td>\n      <td>51.045113</td>\n      <td>100.0</td>\n      <td>Calgary,Alberta,CAN</td>\n      <td>CAN</td>\n      <td>Calgary</td>\n      <td>Alberta</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1820</th>\n      <td>1820</td>\n      <td>1822</td>\n      <td>1824</td>\n      <td>2022</td>\n      <td>2022</td>\n      <td>6/8/2022 3:19</td>\n      <td>6/8/2022 3:30</td>\n      <td>IP Address</td>\n      <td>108.211.181.111</td>\n      <td>100</td>\n      <td>...</td>\n      <td>Other (please specify):</td>\n      <td>acquientance</td>\n      <td>-122.419640</td>\n      <td>37.777120</td>\n      <td>100.0</td>\n      <td>San Francisco,California,USA</td>\n      <td>USA</td>\n      <td>San Francisco</td>\n      <td>California</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>586 rows × 87 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code run the aalysis on the cities with the highest number of answers\n",
    "data_general.groupby('city').count()\n",
    "data_general_city = data_general[data_general['city'].isin(['San Francisco','Seattle','Calgary','Edmonton','Los Angeles'])]\n",
    "data_general_city"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "city\n",
      "Q2_part\tQ6_day_time\tQ7_is_locked\tQ8_locked_type\tQ9_theft_location\tQ10_is_regi\tQ11_report_loc\tQ12_is_insured\tQ13_estimate_val\tQ14_is_electric\tQ15_bike_type\tQ17_is_university\tQ18_is_recovered\tQ19_is_online\tQ20_how_recovered\tQ21_is_police_assist\tQ23_recovery_loc\tQ24_con_recovery\tQ34_1_birth\tQ35_gender\tQ36_income\tQ37_number_of_bicycles \tQ38_education\tQ39_ethnic_origin\t"
     ]
    }
   ],
   "source": [
    "data_path = f'{project_folder}/python/notebooks/output/general/'\n",
    "# analysis by the four city\n",
    "city_data= ['city']\n",
    "other_data ={'Q2': 'part', 'Q6': 'day_time', 'Q7': 'is_locked', 'Q8': 'locked_type', 'Q9': 'theft_location', 'Q10': 'is_regi', 'Q11': 'report_loc', 'Q12': 'is_insured', 'Q13': 'estimate_val', 'Q14': 'is_electric', 'Q15': 'bike_type', 'Q17': 'is_university','Q18':'is_recovered', 'Q19': 'is_online','Q20':'how_recovered', 'Q21': 'is_police_assist', 'Q23': 'recovery_loc', 'Q24': 'con_recovery','Q34_1': 'birth', 'Q35': 'gender', 'Q36': 'income','Q37':'number_of_bicycles ', 'Q38': 'education', 'Q39': 'ethnic_origin'}\n",
    "other_data  = [item for item in other_data.items()]\n",
    "# city_data= [item for item in city_data.items()]\n",
    "bivariate_analysis_update(data_to_group=data_general_city, main_vars_to_group=city_data, secondary_vars=other_data,\n",
    "                          field_to_count='level_0',my_data_path=f'{data_path}/by_city')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}