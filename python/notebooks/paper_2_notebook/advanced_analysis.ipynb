{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:100% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import calendar\n",
    "import prince\n",
    "months = list(map(lambda x: x.lower(), calendar.month_name))[1:]\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 10),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize': 'x-large',\n",
    "          'xtick.labelsize': 'x-large',\n",
    "          'ytick.labelsize': 'x-large'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "import os\n",
    "\n",
    "project_folder = f'{os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))}/data/process'\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "# Set the display width to fit the entire notebook width\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from IPython.display import Markdown\n",
    "from IPython.display import display_html\n",
    "import scipy.stats as stats\n",
    "\n",
    "predictors ={'Q13':'value_approx','Q14':'is_electric','Q15':'bicycle_type','Q18':'is_recover',  'Q28':'seasons', 'Q29':'purpose', 'age_groups': 'age_groups', 'Q35': 'gender', 'Q36': 'income','Q37':'nm_bikes', 'Q38': 'education','country':'country'}\n",
    "dependent_vars = {'Q25':'is_replaced','Q30':'mode_alt', 'Q31':'post_act'}\n",
    "all_vars = predictors.copy()\n",
    "all_vars.update(dependent_vars)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"color: red;font-size: 50px\">RUN THE NEXT CELL FOR THE FIRST TIME ONLY</span>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "# Change col names and leave only relevant cols as well as delete unnecessary spaces and parenthesis (except age group)\n",
    "cols_names = list(all_vars.values())\n",
    "data_init = pd.read_csv(f'{project_folder}/new_data/new_data_2.csv')\n",
    "temp = data_init['age_groups']\n",
    "d_analysis = data_init.rename(columns=all_vars)[cols_names].astype(str).replace(r\"\\(.*?\\)\", \"\").astype(str).replace(\":\", \"\").apply(lambda row: [d.split('(')[0].strip() if '(' in d else d.strip() for d in row])\n",
    "d_analysis['age_groups'] = temp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This method translate the alternative data into how much the alternative is sustainable\n",
    "def sus_alter(row):\n",
    "    alt_stat = ['sustainable','semi','non sustainable']\n",
    "    if row in  ['Walk','Cycle, personal bicycle','Cycle, rental bicycle','Cycle, public bike share','Micro mobility']:\n",
    "        return alt_stat[0]\n",
    "    elif row in ['Transit','Motorcycle or scooter']:\n",
    "        return alt_stat[1]\n",
    "    elif row in ['Car, as a driver','Car, as a passenger','Taxi / Ride-hailing service']:\n",
    "        return alt_stat[2]\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "d_analysis['mode_alt'] = d_analysis['mode_alt'].apply(sus_alter)\n",
    "\n",
    "d_analysis.to_csv(f'{project_folder}/new_data/new_data_3.csv')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# read data\n",
    "merge_q = pd.read_csv(f'{project_folder}/new_data/new_data_3.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# organize and populate @more_data  dictionary\n",
    "more_data ={item:[list(DataFrame(merge_q[item].unique()).dropna()[0]),False] for  item in all_vars.values()}\n",
    "\n",
    "# Code relevant for reindex\n",
    "# Bicycle attributes\n",
    "q= 'value_approx'\n",
    "df_t = DataFrame(merge_q[q].unique()).dropna().sort_values(by=0, ascending=0).reset_index(drop=True)\n",
    "more_data[q][0] = pd.concat([df_t.iloc[0], df_t.iloc[6], df_t.iloc[4], df_t.iloc[8], df_t.iloc[7], df_t.iloc[5], df_t.iloc[1:4].sort_values(by=0, ascending=1)])[0].to_list()\n",
    "\n",
    "# Demographic\n",
    "more_data['education'][0]= ['Some high school or less',\n",
    "                            'Graduated high school',\n",
    "                            'Some university',\n",
    "                            'Associate’s/vocational/technical\\u202fdegree',\n",
    "                            'Bachelor’s degree',\n",
    "                            'Graduate degree',\n",
    "                            'I prefer to not answer',\n",
    " ]\n",
    "q = 'age_groups'\n",
    "more_data[q][0] = DataFrame(merge_q[q].unique()).dropna()[::-1][0].to_list()\n",
    "\n",
    "\n",
    "more_data['seasons'][0] = range(3)\n",
    "q= 'income'\n",
    "df_t = DataFrame(merge_q[q].unique()).dropna().sort_values(by=0, ascending=0).reset_index(drop=True)\n",
    "more_data[q][0]= pd.concat([df_t.iloc[0], df_t.iloc[6:2:-1], df_t.iloc[8:6:-1], df_t.iloc[9], df_t.iloc[1:3]])[0].to_list()\n",
    "q = 'nm_bikes'\n",
    "df_t = DataFrame(merge_q[q].unique()).dropna().sort_values(by=0, ascending=0).reset_index(drop=True)\n",
    "more_data[q][0]= pd.concat([df_t.iloc[0], df_t.iloc[3], df_t.iloc[1:3], df_t.iloc[5:], df_t.iloc[4]])[0].to_list()\n",
    "\n",
    "# for the dependent variable post_act:\n",
    "more_data['post_act'][0]= ['I stopped cycling',\n",
    "                            'Less often',\n",
    "                            'About the same / no change',\n",
    "                            'More often',\n",
    "]\n",
    "# In case where only several cols are relevant\n",
    "more_data['bicycle_type'][0]= more_data['bicycle_type'][1]=['Hybrid/City/Dutch','Mountain','Road','Gravel/cyclocross']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for name in ['value_approx','income','nm_bikes','age_groups','education']:\n",
    "    print(more_data[name][0].index('$250-$499'))\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"color: blue;font-size: 50px\">Find relationships between independent variables </span>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "dependents_list = ['value_approx','income','nm_bikes','age_groups','education']\n",
    "data_to_exp = merge_q[dependents_list].fillna(-1)\n",
    "\n",
    "def to_ordinal(col):\n",
    "    # This function gets a column and return for each value its ordinal values as it stored in @more_data (for irrelevant data return -1)\n",
    "    return data_to_exp[col.name].apply(lambda x:more_data[col.name][0].index(x) if x not in ['I prefer to not answer','Don’t know/not sure',-1] else -1)\n",
    "data_as_ordinal = data_to_exp.apply(to_ordinal)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "          var_1       var_2  correlation       p_value\n1  value_approx    nm_bikes     0.299765  1.175538e-36\n6        income   education     0.281990  2.410065e-29\n4        income    nm_bikes     0.241739  8.763972e-22\n7      nm_bikes  age_groups     0.233628  1.395895e-22\n0  value_approx      income     0.218758  4.698700e-18\n5        income  age_groups     0.212985  3.320104e-17\n2  value_approx  age_groups     0.191486  1.932273e-16\n9    age_groups   education     0.145009  2.140645e-09\n8      nm_bikes   education     0.114911  2.286376e-06\n3  value_approx   education     0.041716  8.701408e-02",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var_1</th>\n      <th>var_2</th>\n      <th>correlation</th>\n      <th>p_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>value_approx</td>\n      <td>nm_bikes</td>\n      <td>0.299765</td>\n      <td>1.175538e-36</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>income</td>\n      <td>education</td>\n      <td>0.281990</td>\n      <td>2.410065e-29</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>income</td>\n      <td>nm_bikes</td>\n      <td>0.241739</td>\n      <td>8.763972e-22</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>nm_bikes</td>\n      <td>age_groups</td>\n      <td>0.233628</td>\n      <td>1.395895e-22</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>value_approx</td>\n      <td>income</td>\n      <td>0.218758</td>\n      <td>4.698700e-18</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>income</td>\n      <td>age_groups</td>\n      <td>0.212985</td>\n      <td>3.320104e-17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>value_approx</td>\n      <td>age_groups</td>\n      <td>0.191486</td>\n      <td>1.932273e-16</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>age_groups</td>\n      <td>education</td>\n      <td>0.145009</td>\n      <td>2.140645e-09</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>nm_bikes</td>\n      <td>education</td>\n      <td>0.114911</td>\n      <td>2.286376e-06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>value_approx</td>\n      <td>education</td>\n      <td>0.041716</td>\n      <td>8.701408e-02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_list = []\n",
    "# The code test every pair of independent variables to find the direction of the correlation\n",
    "for items in [(x, y) for i,x in enumerate(dependents_list) for y in dependents_list[i+1:]]:\n",
    "    var_1, var_2 = items\n",
    "    df = data_as_ordinal[[var_1, var_2 ]]\n",
    "    couple_to_test = df[~(df== -1).any(axis=1)] # remove missing or irrelevant data\n",
    "    correlation, p_value = stats.spearmanr(couple_to_test[var_1],couple_to_test[var_2]) # use spearman to test the data\n",
    "    data_list.append([var_1,var_2,correlation, p_value])\n",
    "sta_spearman_table = DataFrame(data_list,columns=['var_1','var_2','correlation', 'p_value']).sort_values('correlation',ascending=False)\n",
    "sta_spearman_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"color: blue;font-size: 50px\">####</span>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "class MyData:\n",
    "    \"\"\"\n",
    "   The class organizes and explores the data, allowing for the creation of cross-tabulations.\n",
    "    \"\"\"\n",
    "    def __init__(self, var_0, data, com_data):\n",
    "        \"\"\"\n",
    "\n",
    "        :param var_0: The main variable that should not be replaced frequently throughout the program.\n",
    "        :param data: Data frame\n",
    "        :param com_data: provides more information when necessary to create more adaptable analysis\n",
    "        \"\"\"\n",
    "        self.cols_name = [var_0,'']\n",
    "        self.merge_q= data\n",
    "        self.more_data = com_data\n",
    "        self.reindex_rows = self.more_data[var_0][0]\n",
    "    def explore_data(self,cross_tab= True):\n",
    "        r\"\"\"\n",
    "        Clean the data and print cross_tab if it is required\n",
    "        :param cross_tab:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Based on these variables, the analysis can be employed.\n",
    "        cross_cols_nm =self.cols_name\n",
    "        cls_to_use = self.more_data[cross_cols_nm[1]][1]\n",
    "        reindex_temp = self.more_data[cross_cols_nm[1]][0]\n",
    "        only_rel_f= self.merge_q[cross_cols_nm].dropna()\n",
    "        if cross_tab:\n",
    "            if cls_to_use:\n",
    "                only_rel_f = only_rel_f[only_rel_f[cross_cols_nm[1]].isin(cls_to_use)]\n",
    "            # For ordinal categories, reindexing the columns is essential to align them in the required order.\n",
    "            return only_rel_f[cross_cols_nm[1]].value_counts().reindex(reindex_temp), (pd.crosstab(only_rel_f[cross_cols_nm[0]], only_rel_f[cross_cols_nm[1]], normalize='columns') * 100).astype(int).reindex(columns=reindex_temp,index= self.reindex_rows)\n",
    "        return only_rel_f\n",
    "\n",
    "    def change_properties(self,name):\n",
    "        \"\"\"\n",
    "        change the dependent variable and update desired reindex list\n",
    "        :param name:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.cols_name[0] = name\n",
    "        self.reindex_rows = self.more_data[name][0]\n",
    "        sumy =my_data.merge_q[name].value_counts().sum()\n",
    "        print((my_data.merge_q[name].value_counts()/sumy*100).apply('{:.0f}%'.format))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Unnamed: 0', 'value_approx', 'is_electric', 'bicycle_type',\n       'is_recover', 'seasons', 'purpose', 'age_groups', 'gender', 'income',\n       'nm_bikes', 'education', 'country', 'is_replaced', 'mode_alt',\n       'post_act'],\n      dtype='object')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_q.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "is_replaced\n",
      "\n",
      "​Yes, and I replaced it with exactly what was stolen or something more expensive    46%\n",
      "No                                                                                  31%\n",
      "Yes, but the replacement was something cheaper                                      24%\n",
      "Name: is_replaced, dtype: object\n",
      "\n",
      "mode_alt\n",
      "\n",
      "non sustainable            39%\n",
      "sustainable                36%\n",
      "Didn’t make those trips    13%\n",
      "semi                       10%\n",
      "Don’t know/not sure         2%\n",
      "Name: mode_alt, dtype: object\n",
      "\n",
      "post_act\n",
      "\n",
      "About the same / no change    49%\n",
      "Less often                    30%\n",
      "I stopped cycling             15%\n",
      "More often                     6%\n",
      "Name: post_act, dtype: object\n",
      "\n",
      "value_approx\n",
      "\n",
      "$500-$999                 29%\n",
      "$1000-$1999               24%\n",
      "$2000-3999                16%\n",
      "$250-$499                 13%\n",
      "$4000-6999                 8%\n",
      "$7000 or more              5%\n",
      "Less than $250             4%\n",
      "Don’t know/not sure        0%\n",
      "I prefer to not answer     0%\n",
      "Name: value_approx, dtype: object\n",
      "\n",
      "income\n",
      "\n",
      "$200,000 or more per year                 21%\n",
      "Between $100,000 and $149,999 per year    16%\n",
      "Between $75,000 and $99,999 per year      14%\n",
      "Between $50,000 and $74,999 per year      13%\n",
      "Between $150,000 and $199,999 per year    10%\n",
      "I prefer to not answer                     9%\n",
      "Between $20,000 and $34,999 per year       6%\n",
      "Between $35,000 and $49,999 per year       5%\n",
      "Under $20,000 per year                     5%\n",
      "Don’t know/not sure                        1%\n",
      "Name: income, dtype: object\n",
      "\n",
      "nm_bikes\n",
      "\n",
      "One                       37%\n",
      "Two                       24%\n",
      "Zero                      12%\n",
      "Three                     12%\n",
      "Five or more               8%\n",
      "Four                       6%\n",
      "I prefer to not answer     1%\n",
      "Name: nm_bikes, dtype: object\n",
      "\n",
      "age_groups\n",
      "\n",
      "Adults (25-34)          27%\n",
      "Adults (35-44)          25%\n",
      "Adults (45-54)          17%\n",
      "Older adults (>64)      15%\n",
      "Adults (55-64)          10%\n",
      "Young adults (18-24)     5%\n",
      "Adolescents (13-17)      1%\n",
      "Children (<13)           0%\n",
      "Name: age_groups, dtype: object\n",
      "\n",
      "education\n",
      "\n",
      "Graduate degree                            41%\n",
      "Bachelor’s degree                          39%\n",
      "Some university                             7%\n",
      "Associate’s/vocational/technical degree     6%\n",
      "Graduated high school                       3%\n",
      "Some high school or less                    2%\n",
      "I prefer to not answer                      2%\n",
      "Name: education, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dependent_names = list(dependent_vars.values())+['value_approx','income','nm_bikes','age_groups','education']\n",
    "predictors_names = list(predictors.values())\n",
    "my_data = MyData(dependent_names[0],merge_q,more_data)\n",
    "for dep in dependent_names:\n",
    "    print(f'\\n{dep}\\n')\n",
    "    writer = pd.ExcelWriter(f'output_2/data_with_insight/{dep}.xlsx')\n",
    "    my_data.change_properties(dep)\n",
    "    for pre in predictors_names+dependent_names:\n",
    "        # relevant when we analysis the relationship between dependent_vars\n",
    "        if pre==dep:\n",
    "            continue\n",
    "        my_data.cols_name[1] = pre\n",
    "        value_counts,cross_tab = my_data.explore_data()\n",
    "        value_counts.to_excel(writer, sheet_name=pre)\n",
    "        cross_tab.to_excel(writer, sheet_name=pre, startrow=value_counts.shape[0] + 2)\n",
    "    writer.save()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ver_to_test =[{'value_approx','income'},{'value_approx','nm_bikes'},{'value_approx','education'},\n",
    "#               {'nm_bikes','value_approx'},{'nm_bikes','income'},{'nm_bikes','education'},\n",
    "#               {'income','value_approx'},{'income','nm_bikes'},{'income','nm_bikes'},{'income','age_groups'},{'income','education'},\n",
    "#               {'age_groups','nm_bikes'},{'age_groups','education'},\n",
    "#               {'education','income'}]\n",
    "# cols_to_exclude = ['I prefer to not answer','Don’t know/not sure','Children (<13)']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "#\n",
    "def calculate_chi_cross_tab(two_var_tables):\n",
    "    r\"\"\"\n",
    "    This function creates new groups based on the data in @vars, cross tab them and calculate Chi-square\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # the new names for the variables which be presented on the cross tabulation tabel\n",
    "    new_names = [t['var'] for t in my_vars]\n",
    "    two_var_tables[new_names] = two_var_tables.apply(lambda x: [x[t['q']] if x[t['q']] in t['group'] else t['group2'] for t in my_vars],axis=1,result_type='expand')\n",
    "    cont_table = pd.crosstab([two_var_tables[t['var']] for t in my_vars[:-1]],two_var_tables[my_vars[-1]['var']],normalize='columns')*100\n",
    "\n",
    "    # perform chi-square test of independence\n",
    "    chi2, p, dof, expected = chi2_contingency(cont_table)\n",
    "\n",
    "    # print the test results\n",
    "    print(f\"Chi-square statistic: {chi2:.2f}\")\n",
    "    print(f\"P-value: {p:.5f}\")\n",
    "    print(cont_table)\n",
    "    if to_print:\n",
    "        cont_table.to_csv(to_print)\n",
    "\n",
    "def prep_for_chi(only_rel_f,grp:dict):\n",
    "    r\"\"\"\n",
    "    this function store and set the data so only the relevant data will be used to calculate chi -square\n",
    "    :param only_rel_f:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # working only with information stored in list in @rel_data for a specific col\n",
    "    for i in range(1,len(rel_data),2):\n",
    "        if rel_data[i]:\n",
    "            only_rel_f= only_rel_f[only_rel_f[rel_data[i-1][0]].isin(rel_data[i])] if rel_data[i-1][1] else only_rel_f[~only_rel_f[rel_data[i-1][0]].isin(rel_data[i])]\n",
    "    # group data\n",
    "    for q_temp in grp.keys():\n",
    "        grp_inf = grp[q_temp]\n",
    "        only_rel_f[q_temp] = only_rel_f[q_temp].apply(lambda x:grp_inf[0] if x in grp_inf[1] else grp_inf[2])\n",
    "\n",
    "    calculate_chi_cross_tab(only_rel_f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}